{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "802b54c6",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# **심화도전2**\n",
    "# ### **Breast cancer wisconsin 데이터를 이용한 <span style=\"color:darkgreen\">AI분류</span> 문제**\n",
    "# ---\n",
    "\n",
    "# #### 암세포의 형태 데이터를 이용하여 암 진단 판정을 악성과 양성으로 분류하는 AI문제입니다. \n",
    "# #### AI코딩 단계에 따라 주어지는 문제를 읽고 답안을 작성하세요.\n",
    "# #### ( Breast cancer wisconsin 데이터 : sklearn 내장 연습용 데이터셋 사용)\n",
    "# \n",
    "#  - 데이터 : 분류(카테고리)\n",
    "#  - 모델 : KNN(머신러닝 모델 비교 분석), DeepLearning\n",
    "#  - 주요 전처리 : 분석 Column 추가, 표준화(standardization)\n",
    "#  - 주요 학습 내용 : 이중 분류 모델 생성(binary 분류, input, output 처리, 손실함수 등), 머신러닝 모델 비교학습(리스트 활용)\n",
    "# ---\n",
    "# \n",
    "# **아래 측정값들을, 평균(mean), 표준오차(error), 제일 큰 값 3개의 평균(worst)으로 나타낸다. 예를 들어 radius는 mean radius, radius error, worst radius 3개 컬럼으로 나타난다.**<br>\n",
    "# \n",
    "# - radius : 암세포의 반지름\n",
    "# - texture : 질감\n",
    "# - perimeter : 둘레\n",
    "# - area : 면적\n",
    "# - smoothness : 매끄러움\n",
    "# - concavity : 오목함\n",
    "# - concave points : 오목한 곳의 수\n",
    "# - symmetry : 대칭성\n",
    "# - fractal dimension : 프렉탈 차원\n",
    "# - class : 라벨(y변수) 데이터로 세포의 양성/악성 여부를 binary로 표기한 데이터\n",
    "#     * 0 : malignant : 악성\n",
    "#     * 1 : benign : 양성\n",
    "# \n",
    "\n",
    "# ---\n",
    "# > **<span style=\"color:red\">다음 문항을 풀기 전에 </span>아래 코드를 실행하시오.**<br>\n",
    "# > **sklearn에서 제공하는 load_breast_cacncer에 대한 데이터를 불러올 예정입니다. <span style=\"color:darkgreen\"></span>**<br>\n",
    "# > ** 해당 형태로 불러온 데이터는 AIDU 환경변수와 상관없이 사용할수 있습니다.<br>\n",
    "# > 분석할 feautre 데이터는 x 변수에, 라벨은 y변수에 저장 되게 됩니다.(사전 x,y 데이터 분리 실행)\n",
    "# > y변수는 상기 서술된 컬럼 중 class 항목입니다.\n",
    "# \n",
    "# \n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48f76e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "x = cancer.data # 인풋으로 사용할 데이터\n",
    "y = cancer.target # 아웃풋, target으로 사용할 데이터\n",
    "col_names = cancer.feature_names # 인풋으로 사용할 데이터의 컬럼별 이름들\n",
    "target_names = cancer.target_names # 아웃풋, target으로 사용할 데이터의 클래스 이름\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057866a7",
   "metadata": {},
   "source": [
    "# ### **Q1. pandas를 pd로 alias하여 사용할 수 있도록 불러오는 코드를 작성하고 실행하시기 바랍니다.**\n",
    "# ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a205447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608d582c",
   "metadata": {},
   "source": [
    "# ### **Q2.Matplotlib의 pyplot을 plt로 alias하여 사용할 수 있도록 불러오는 코드를 작성하고 실행하시기 바랍니다.**\n",
    "# ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abe080cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161ac77a",
   "metadata": {},
   "source": [
    "# ### **Q3. 인풋데이터(x)와 인풋데이터 컬럼명(col_names)를 이용하여 인풋데이터의 dataframe을 제작하시기 바랍니다.**\n",
    "# * **\n",
    "# - 데이터 프레임의 변수 명은 bcc 로 한다.\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d538d479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "bcc = pd.DataFrame(cancer.data, columns = col_names)\n",
    "bcc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209f7b08",
   "metadata": {},
   "source": [
    "\n",
    "# ### **Q4. 데이터를 트레이닝셋 / 테스트셋으로 분할하시기 바랍니다.**\n",
    "# * **\n",
    "# - bcc와, y를 이용한다. ( x를 사용해도 좋지만, 이후 문제를 위해 bcc를 이용한다.)\n",
    "# - train : test = 8.5 : 1.5\n",
    "# - y의 클래스가 골고루 분할되도록 stratify하게 분할한다.\n",
    "# - 변수명 규칙은 다음과 같다.\n",
    "#     * x_train, y_train\n",
    "#     * x_test, y_test\n",
    "# - random state, seed 등은 2021로 설정한다.\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac8a182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15,  stratify = y, random_state=2021)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e5f5b4",
   "metadata": {},
   "source": [
    "# ### **Q5. 트레이닝 데이터를 트레이닝셋 / 벨리데이션셋으로 분할하시기 바랍니다.**\n",
    "# * **\n",
    "# - x_train, y_train을 이용한다.\n",
    "# - train : validation = 7 : 3\n",
    "# - y_train의 클래스가 골고루 분할되도록 stratify하게 분할한다.\n",
    "# - 변수명 규칙은 다음과 같다.\n",
    "#     * x_train, y_train\n",
    "#     * y_valid, y_valid\n",
    "# - random state, seed 등은 2021로 설정한다.\n",
    "# ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "243ec656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(359, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.255,  stratify = y_train, random_state=2021)\n",
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374448db",
   "metadata": {},
   "source": [
    "\n",
    "# ### **Q6. x_train, x_valid, x_test의 인덱스를 초기화 하시기 바랍니다.**\n",
    "# * **\n",
    "# - 현재 x들은 전부 dataframe이고, 원본 bcc의 인덱스를 그대로 가지고 있다.\n",
    "# - 맨 첫번째 row부터 순서대로 인덱스를 갖도록 한다\n",
    "# - 인덱스는 정수 인덱스이며, 0부터 시작한다.\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9709c788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>564</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>565</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>566</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>567</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>568</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  mean radius  mean texture  mean perimeter  mean area  \\\n",
       "0        0        17.99         10.38          122.80     1001.0   \n",
       "1        1        20.57         17.77          132.90     1326.0   \n",
       "2        2        19.69         21.25          130.00     1203.0   \n",
       "3        3        11.42         20.38           77.58      386.1   \n",
       "4        4        20.29         14.34          135.10     1297.0   \n",
       "..     ...          ...           ...             ...        ...   \n",
       "564    564        21.56         22.39          142.00     1479.0   \n",
       "565    565        20.13         28.25          131.20     1261.0   \n",
       "566    566        16.60         28.08          108.30      858.1   \n",
       "567    567        20.60         29.33          140.10     1265.0   \n",
       "568    568         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     mean symmetry  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0           0.2419  ...        25.380          17.33           184.60   \n",
       "1           0.1812  ...        24.990          23.41           158.80   \n",
       "2           0.2069  ...        23.570          25.53           152.50   \n",
       "3           0.2597  ...        14.910          26.50            98.87   \n",
       "4           0.1809  ...        22.540          16.67           152.20   \n",
       "..             ...  ...           ...            ...              ...   \n",
       "564         0.1726  ...        25.450          26.40           166.10   \n",
       "565         0.1752  ...        23.690          38.25           155.00   \n",
       "566         0.1590  ...        18.980          34.12           126.70   \n",
       "567         0.2397  ...        25.740          39.42           184.60   \n",
       "568         0.1587  ...         9.456          30.37            59.16   \n",
       "\n",
       "     worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0        2019.0           0.16220            0.66560           0.7119   \n",
       "1        1956.0           0.12380            0.18660           0.2416   \n",
       "2        1709.0           0.14440            0.42450           0.4504   \n",
       "3         567.7           0.20980            0.86630           0.6869   \n",
       "4        1575.0           0.13740            0.20500           0.4000   \n",
       "..          ...               ...                ...              ...   \n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcc.reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c86808",
   "metadata": {},
   "source": [
    "\n",
    "# ### **Q7. x_train, x_valid, x_test의 모든 컬럼을 각각 표준화(standardization) 스케일링 하시기 바랍니다.**\n",
    "# * **\n",
    "# - **모든 전처리 규칙은 트레이닝셋으로 부터 선정한다.**\n",
    "# - 스케일링한 x들은 각각 아래의 변수에 따로 선언해둔다.\n",
    "#     * x_train_sc\n",
    "#     * x_valid_sc\n",
    "#     * x_test_sc\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "675c008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "\n",
    "scaler.fit(x_train)\n",
    "x_train_sc = scaler.transform(x_train)\n",
    "\n",
    "scaler.fit(x_valid)\n",
    "x_valid_sc = scaler.transform(x_valid)\n",
    "\n",
    "scaler.fit(x_test)\n",
    "x_test_sc = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a00a70",
   "metadata": {},
   "source": [
    "# ### **Q8. KNN 모델들을 학습시키시기 바랍니다.**\n",
    "# * **\n",
    "# - 트레이닝 셋 (x_train_sc, y_train)을 이용하여 학습시킨다.\n",
    "# - KNN의 이웃수(k)를 2부터 15까지 늘려가며 총 14개의 모델을 학습시킨다.\n",
    "# - 학습시킨 트리들은 리스트를 만들어 knns 변수에 담아둔다.\n",
    "# - y를 예측할 경우, 이웃들의 거리값은 반영하지 않는다.(weights 파라미터는 uniform을 사용한다.)\n",
    "# - 각 모델을 knns 라는 list에 순차적으로 저장하시기 바랍니ㅣ다.\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "758821aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "k_param = range(2,16)\n",
    "knns = []\n",
    "\n",
    "for k in k_param:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights = \"uniform\")\n",
    "    knns.append(knn.fit(x_train_sc, y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8596ec",
   "metadata": {},
   "source": [
    "# ### **Q9. KNN 모델들의 성능을 리스트에 담아 accs에 선언하시기 바랍니다.**\n",
    "# * **\n",
    "# - k가 2인 knn모델부터 순서대로 평가하여 리스트에 담는다.\n",
    "# - 벨리데이션 셋 위에서 성능을 평가한다. (x는 스케일링 된 값이어야 한다.)\n",
    "# - 성능지표로는 accuracy를 사용한다.\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c18a162a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9435483870967742\n",
      "0.967741935483871\n",
      "0.967741935483871\n",
      "0.9516129032258065\n",
      "0.9596774193548387\n",
      "0.9596774193548387\n",
      "0.9596774193548387\n",
      "0.967741935483871\n",
      "0.9596774193548387\n",
      "0.967741935483871\n",
      "0.9596774193548387\n",
      "0.967741935483871\n",
      "0.967741935483871\n",
      "0.9596774193548387\n"
     ]
    }
   ],
   "source": [
    "accs=[]\n",
    "for i in range(14):\n",
    "    print(knns[i].score(x_valid_sc, y_valid))\n",
    "    accs.append(knns[i].score(x_valid_sc, y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1863d335",
   "metadata": {},
   "source": [
    "# ### **Q10. KNN모델들의 k(이웃수)에 따른 accuracy를 시각화 하고, 가장 성능이 좋은 k 값을 선택하시기 바랍니다.**\n",
    "# * **\n",
    "# - 위의 Q9에서 제작한 리스트 accs를 이용한다.\n",
    "# - line plot 이나 scatter plot을 이용한다.\n",
    "# - 동일 성능의 k가 여러개라면, 가장 작은 k를 선택한다.\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "332f33df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accs)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.title(\"Breast Cancer Classifier Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "a = accs.index(max(accs))\n",
    "k = knns[a]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426e7374",
   "metadata": {},
   "source": [
    "# ### **Q11. 선택된 KNN모델의 테스트셋 위에서의 accuracy를 출력하시기 바랍니다.**\n",
    "# * **\n",
    "# - 성능 확인 시 입력데이터는 스케일링 된 데이터인 x_test_sc를 사용해야 한다.\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9700327b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9651162790697675"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "k.score(x_test_sc, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5997272f",
   "metadata": {},
   "source": [
    "# ### **Q12. 해당 모델의 classificaiton report를 출력하고, malignant의 precision 값을 출력하시오**\n",
    "# ---\n",
    "#   - 테스트셋 위의 성능 평가를 바탕으로 문제를 푼다.\n",
    "#   - 성능 확인 시 입력데이터는 스케일링 된 데이터인 x_test_sc를 사용해야 한다.\n",
    "# ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0698b87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      y_test       0.94      0.97      0.95        32\n",
      "   y_test_sc       0.98      0.96      0.97        54\n",
      "\n",
      "    accuracy                           0.97        86\n",
      "   macro avg       0.96      0.97      0.96        86\n",
      "weighted avg       0.97      0.97      0.97        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_test_sc = k.predict(x_test_sc)\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = ['y_test','y_test_sc'] # target values\n",
    "\n",
    "# Print classification report after a train/test split:\n",
    "print(classification_report(y_test,y_test_sc, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c945810c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9393939393939394"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_test,y_test_sc, pos_label = 0)\n",
    "#앞이 실제 뒤가 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e5a99a",
   "metadata": {},
   "source": [
    "# ### **Q13. Q8에서 Q11 까지의 학습 과정을 scaling 되지 않은 원본데이터로 학습하여 별도의 모델을 만드시기 바랍니다.**\n",
    "# * **\n",
    "# - 해당 모델의 classificaiton report를 출력하고, malignant의 precision 값을 출력하시오\n",
    "#     - 테스트셋 위의 성능 평가를 바탕으로 문제를 푼다.\n",
    "#     - 성능 확인 시 입력데이터는 스케일링 하지 않은 데이터인 x_valid를 사용해야 한다.\n",
    "# ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fec49791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     y_valid       0.37      1.00      0.54        46\n",
      "  y_valid_sc       0.00      0.00      0.00        78\n",
      "\n",
      "    accuracy                           0.37       124\n",
      "   macro avg       0.19      0.50      0.27       124\n",
      "weighted avg       0.14      0.37      0.20       124\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3709677419354839"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid_sc = k.predict(x_valid)\n",
    "target_names = ['y_valid','y_valid_sc'] # target values\n",
    "# Print classification report after a train/test split:\n",
    "print(classification_report(y_valid,y_valid_sc, target_names=target_names))\n",
    "\n",
    "precision_score(y_valid,y_valid_sc, pos_label = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dcfd23",
   "metadata": {},
   "source": [
    "# ### **Q14. 스케일링하지 않은 데이터의 예측 모델 성능과, 스케일링한 데이터의 예측모델 성능을 출력하여 비교하시기 바랍니다.**\n",
    "# * **\n",
    "# - 기존 만든 best_knn 모델의 score를 사용하여 성능을 출력할 것\n",
    "# - 스케일링한 학습 모델은 데이터 : x_test_sc 활용\n",
    "# - 스케일링하지 않은 모델은 데이터 x_test 활용\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8799377e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9651162790697675\n",
      "0.37209302325581395\n"
     ]
    }
   ],
   "source": [
    "print(k.score(x_test_sc, y_test))\n",
    "print(k.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b86b980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b0dd96",
   "metadata": {},
   "source": [
    "# ### **Q16. 아래 조건에 맞추어 뉴럴네트워크 모델을 학습시키시기 바랍니다**\n",
    "# * **\n",
    "# - Tensorflow framework를 사용한다.\n",
    "# - 히든레이어는 아래와 같은 규칙에 맞추어 구성합니다.\n",
    "#     * 3개 이상의 fully connected layer를 사용할 것\n",
    "#     * Drop out과 batchnormalization을 각각 한번 이상 사용한다.\n",
    "# - Early stopping을 이용하여, validation loss가 10번 이상 개선되지 않으면 학습을 중단 시키고, 가장 성능이 좋았을 때의 가중치를 복구한다.\n",
    "# - 학습과정의 로그(loss, accuracy)를 history에 선언하여 남긴다.\n",
    "# - y를 별도로 원핫인코딩 하지 않고 분류모델을 학습시킬 수 있도록 한다.\n",
    "# - 0,1로 구분된 binary 분류모델에 맞는 loss function인 binary_crossentropy를 사용하도록 한다.\n",
    "# - epochs는 2000번을 지정한다.\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da040c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
